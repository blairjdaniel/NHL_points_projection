{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import requests\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import requests\n",
    "import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of all NHL teams from 2008 onwards\n",
    "teams = [\n",
    "#     \n",
    "    \"BOS\",  # Boston Bruins\n",
    "    \"ANA\",  # Anaheim Ducks\n",
    "    \"BUF\",  # Buffalo Sabres\n",
    "    \"CAR\",  # Carolina Hurricanes\n",
    "    \"CBJ\",  # Columbus Blue Jackets\n",
    "    \"CGY\",  # Calgary Flames\n",
    "    \"CHI\",  # Chicago Blackhawks\n",
    "    \"COL\",  # Colorado Avalanche\n",
    "    \"DAL\",  # Dallas Stars\n",
    "    \"DET\",  # Detroit Red Wings\n",
    "    \"EDM\",  # Edmonton Oilers\n",
    "    \"FLA\",  # Florida Panthers\n",
    "    \"LAK\",  # Los Angeles Kings\n",
    "    \"MIN\",  # Minnesota Wild\n",
    "    \"MTL\",  # Montreal Canadiens\n",
    "    \"NJD\",  # New Jersey Devils\n",
    "    \"NSH\",  # Nashville Predators\n",
    "    \"NYI\",  # New York Islanders\n",
    "    \"NYR\",  # New York Rangers\n",
    "    \"OTT\",  # Ottawa Senators\n",
    "    \"PHI\",  # Philadelphia Flyers\n",
    "    \"PIT\",  # Pittsburgh Penguins\n",
    "    \"SEA\",  # Seattle Kraken\n",
    "    \"SJS\",  # San Jose Sharks\n",
    "    \"STL\",  # St. Louis Blues\n",
    "    \"TBL\",  # Tampa Bay Lightning\n",
    "    \"TOR\",  # Toronto Maple Leafs\n",
    "    \"UTA\",  # Utah Hockey Club\n",
    "    \"VAN\",  # Vancouver Canucks\n",
    "    \"VGK\",  # Vegas Golden Knights\n",
    "    \"WPG\",  # Winnipeg Jets\n",
    "    \"WSH\"   # Washington Capitals\n",
    "    \"ARI\"   # Arizona Coyotes\n",
    "    \"ATL\"   # Atlanta Thrashers \n",
    "    \"HFD\"   # Hartford\n",
    "    \"PHX\"   # Pheonix\n",
    "    \"QUE\"   # Quebec\n",
    "    \"WIN\"   # Winnepeg Jets - Old\n",
    "    ]\n",
    "\n",
    "seasons = [\n",
    "\n",
    "    \"20082009\", \"20092010\",\n",
    "    \"20102011\", \"20112012\", \"20122013\", \"20132014\", \"20142015\",\n",
    "    \"20152016\", \"20162017\", \"20172018\", \"20182019\", \"20192020\",\n",
    "    \"20202021\", \"20212022\", \"20222023\", \"20232024\", \"20242025\"\n",
    "]\n",
    "\n",
    "# Function to get player data from the NHL API\n",
    "def get_player_data(team, season):\n",
    "    url = f\"https://api-web.nhle.com/v1/roster/{team}/{season}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the response is valid JSON\n",
    "    try:\n",
    "        return response.json()\n",
    "    except requests.JSONDecodeError:\n",
    "        print(f\"Error decoding JSON for team {team} in season {season}\")\n",
    "        return {}\n",
    "\n",
    "# Initialize a dictionary to store player IDs\n",
    "player_ids = {}\n",
    "\n",
    "# Loop through each season in the seasons list\n",
    "for season in seasons:\n",
    "    player_ids[season] = {}\n",
    "\n",
    "    # Loop through each team\n",
    "    for team in teams:\n",
    "        try:\n",
    "            # Get the player data for the team and season\n",
    "            player_data = get_player_data(team, season)\n",
    "        \n",
    "            # Initialize dictionaries for defencemen, forwards, and goalies\n",
    "            player_ids[season][team] = {\n",
    "                #'defencemen': [],\n",
    "                'forwards': [],\n",
    "                #'goalies': []\n",
    "            }\n",
    "        \n",
    "            # # Extract player IDs from defencemen\n",
    "            # if 'defensemen' in player_data:\n",
    "            #     for player in player_data['defensemen']:\n",
    "            #         player_id = player['id']\n",
    "            #         player_ids[season][team]['defencemen'].append(player_id)\n",
    "        \n",
    "            # Extract player IDs from forwards\n",
    "            if 'forwards' in player_data:\n",
    "                for player in player_data['forwards']:\n",
    "                    player_id = player['id']\n",
    "                    player_ids[season][team]['forwards'].append(player_id)\n",
    "        \n",
    "            # # Extract player IDs from goalies\n",
    "            # if 'goalies' in player_data:\n",
    "            #     for player in player_data['goalies']:\n",
    "            #         player_id = player['id']\n",
    "            #         player_ids[season][team]['goalies'].append(player_id)\n",
    "    \n",
    "        except KeyError:\n",
    "            print(f\"Team {team} not found for season {season}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "#Print the player IDs\n",
    "pprint.pprint(player_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get game logs for a specific season\n",
    "def get_game_log(player_id, season):\n",
    "    url = f\"https://api-web.nhle.com/v1/player/{player_id}/game-log/{season}/2\"\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "# Check if the response is valid JSON\n",
    "    try:\n",
    "        return response.json()\n",
    "    except requests.JSONDecodeError:\n",
    "        print(f\"Error decoding JSON for player {player_id} in season {season}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to aggregate game logs for a specific player_id\n",
    "def aggregate_game_logs(game_logs):\n",
    "    aggregated_data = {}\n",
    "    \n",
    "    for game in game_logs:\n",
    "        for key, value in game.items():\n",
    "            if key not in aggregated_data:\n",
    "                aggregated_data[key] = value\n",
    "            else:\n",
    "                # If the key already exists, aggregate the data (e.g., sum the values)\n",
    "                if isinstance(value, (int, float)):\n",
    "                    aggregated_data[key] += value\n",
    "                elif isinstance(value, list):\n",
    "                    aggregated_data[key].extend(value)\n",
    "                # Handle other data types as needed\n",
    "    \n",
    "    return aggregated_data\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a dictionary to store DataFrames for each player_id\n",
    "player_dfs = {}\n",
    "\n",
    "# Loop through the selected player_ids\n",
    "for season, teams in player_ids.items():\n",
    "    for team, players in teams.items():\n",
    "        for player_type, player_ids in players.items():\n",
    "            for player_id in player_ids:\n",
    "                game_log = get_game_log(player_id, season)\n",
    "                \n",
    "                if game_log and 'gameLog' in game_log:\n",
    "                    game_log_data = game_log['gameLog']\n",
    "\n",
    "                    seasons_list = []\n",
    "                    # Retrieve relevant stats I may want to use from the game_log dict\n",
    "                    for stat in game_log_data:\n",
    "                        stats_info = {\n",
    "                        'gameDate': stat.get('gameDate'),\n",
    "                        'homeRoadFlag': stat.get('homeRoadFlag'),\t\n",
    "                        'goals': stat.get('goals'),\t\n",
    "                        'assists': stat.get('assists'),\t\n",
    "                        'points': stat.get('points'),\t\n",
    "                        'plusMinus': stat.get('plusMinus'),\t\n",
    "                        'powerPlayGoals': stat.get('powerPlayGoals'),\t\n",
    "                        'powerPlayPoints': stat.get('powerPlayGoals'),\t\n",
    "                        'gameWinningGoals': stat.get('gameWinningGoals'),\t\n",
    "                        'otGoals': stat.get('otGoals'),\t\n",
    "                        'shots': stat.get('shots'),\t\n",
    "                        'shifts': stat.get('shifts'),\t\n",
    "                        'opponentAbbrev': stat.get('opponentAbbrev'),\t\n",
    "                        'pim': stat.get('pim'),\t\n",
    "                        'toi': stat.get('toi'),    \n",
    "                            \n",
    "                        }\n",
    "                        seasons_list.append(stats_info)\n",
    "                    \n",
    "                    # Create df from the flattened list of data\n",
    "                    player_df = pd.DataFrame(seasons_list)\n",
    "\n",
    "                    # Add the DataFrame to the player_dfs dictionary\n",
    "                    player_dfs[player_id] = player_df\n",
    "\n",
    "  \n",
    "                  # Save the DataFrame to a CSV file in the specified folder\n",
    "                    csv_filename = os.path.join('/Users/blairjdaniel/lighthouse/lighthouse/NHL/files/nhlapiforwards', f'player_{player_id}.csv')\n",
    "                    player_df.to_csv(csv_filename, index=False)\n",
    "                    print(f\"DataFrame for player_id {player_id} saved to {csv_filename}\")\n",
    "                else:\n",
    "                    print(f\"No valid data found for player_id {player_id} in season {season}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load all CSV files into a dictionary of DataFrames\n",
    "def load_all_csv_files(directory):\n",
    "    csv_files = glob.glob(os.path.join(directory, '/Users/blairjdaniel/lighthouse/lighthouse/NHL/files/nhlapiforwards/player_*.csv'))\n",
    "    dataframes = {}\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        player_id = os.path.basename(csv_file).split('_')[1].split('.')[0]\n",
    "        # Create a try/except to check for missing values and continue past them\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            if not df.empty:\n",
    "                dataframes[player_id] = df\n",
    "            else:\n",
    "                print(f\"Warning: {csv_file} is empty and will be skipped.\")\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Error: {csv_file} is empty and will be skipped.\")\n",
    "    \n",
    "    return dataframes\n",
    "\n",
    "# Specify the directory where the CSV files are saved\n",
    "directory = '.'  # Current directory\n",
    "\n",
    "# Load all CSV files into a dictionary of DataFrames\n",
    "player_dfs = load_all_csv_files(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a new DataFrame grouped by homeRoadFlag, aggregate by sum and count\n",
    "def create_grouped_df(df):\n",
    "    grouped_df = df.groupby('homeRoadFlag').agg({\n",
    "        'gameDate': 'count',\n",
    "        'goals': 'sum',\n",
    "        'assists': 'sum',\n",
    "        'points': 'sum',\n",
    "        'plusMinus': 'sum',\n",
    "        'powerPlayGoals': 'sum',\n",
    "        'powerPlayPoints': 'sum',\n",
    "        'gameWinningGoals': 'sum',\n",
    "        'otGoals': 'sum',\n",
    "        'shots': 'sum',\n",
    "        'shifts': 'sum',\n",
    "        'pim': 'sum',\n",
    "        \n",
    "    }).rename(columns={'gameDate': 'gameCount'})\n",
    "    # Sum the grouped statistics to create a single row DataFrame\n",
    "    single_row_df = grouped_df.sum().to_frame().T\n",
    "    \n",
    "    return single_row_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each DataFrame and create a grouped DataFrame\n",
    "grouped_dfs = {}\n",
    "for player_id, df in player_dfs.items():\n",
    "    try:\n",
    "        # Check if 'gameDate' column has values\n",
    "        if df['gameDate'].empty:\n",
    "            print(f\"No gameDate values found for player_id {player_id}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Check if 'homeRoadFlag' column exists\n",
    "        if 'homeRoadFlag' in df.columns:\n",
    "            grouped_df = create_grouped_df(df)\n",
    "            grouped_dfs[player_id] = grouped_df\n",
    "        else:\n",
    "            print(f\"'homeRoadFlag' column not found for player_id {player_id}. Skipping...\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for player_id {player_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all DataFrames into a master DataFrame\n",
    "master_df = pd.concat(grouped_dfs.values(), keys=grouped_dfs.keys(), names=['player_id', 'index'])\n",
    "\n",
    "# Reset the index to have 'player_id' as a column\n",
    "master_df.reset_index(level='index', drop=True, inplace=True)\n",
    "master_df.to_csv('/Users/blairjdaniel/lighthouse/lighthouse/NHL/files/master_copies/forwards.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
